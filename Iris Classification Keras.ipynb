{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepalLength</th>\n",
       "      <th>sepalWidth</th>\n",
       "      <th>petalLength</th>\n",
       "      <th>petalWidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepalLength  sepalWidth  petalLength  petalWidth        class\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa\n",
       "5          5.4         3.9          1.7         0.4  Iris-setosa\n",
       "6          4.6         3.4          1.4         0.3  Iris-setosa\n",
       "7          5.0         3.4          1.5         0.2  Iris-setosa\n",
       "8          4.4         2.9          1.4         0.2  Iris-setosa\n",
       "9          4.9         3.1          1.5         0.1  Iris-setosa"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datos= df.values[:,:4]\n",
    "etiquetas= df.values[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(etiquetas)\n",
    "encoded_Y = encoder.transform(etiquetas)\n",
    "etiquetas_ = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(datos, etiquetas_, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0425 - acc: 0.1417\n",
      "Epoch 2/150\n",
      "120/120 [==============================] - 0s 433us/step - loss: 0.9905 - acc: 0.2167\n",
      "Epoch 3/150\n",
      "120/120 [==============================] - 0s 400us/step - loss: 0.9516 - acc: 0.3167\n",
      "Epoch 4/150\n",
      "120/120 [==============================] - 0s 416us/step - loss: 0.9228 - acc: 0.3250\n",
      "Epoch 5/150\n",
      "120/120 [==============================] - 0s 441us/step - loss: 0.8968 - acc: 0.3250\n",
      "Epoch 6/150\n",
      "120/120 [==============================] - 0s 458us/step - loss: 0.8696 - acc: 0.4583\n",
      "Epoch 7/150\n",
      "120/120 [==============================] - 0s 458us/step - loss: 0.8446 - acc: 0.6500\n",
      "Epoch 8/150\n",
      "120/120 [==============================] - 0s 425us/step - loss: 0.8161 - acc: 0.6583\n",
      "Epoch 9/150\n",
      "120/120 [==============================] - 0s 433us/step - loss: 0.7862 - acc: 0.6583\n",
      "Epoch 10/150\n",
      "120/120 [==============================] - 0s 566us/step - loss: 0.7626 - acc: 0.6833\n",
      "Epoch 11/150\n",
      "120/120 [==============================] - 0s 491us/step - loss: 0.7328 - acc: 0.6750\n",
      "Epoch 12/150\n",
      "120/120 [==============================] - 0s 508us/step - loss: 0.7074 - acc: 0.6583\n",
      "Epoch 13/150\n",
      "120/120 [==============================] - 0s 525us/step - loss: 0.6842 - acc: 0.6667\n",
      "Epoch 14/150\n",
      "120/120 [==============================] - 0s 541us/step - loss: 0.6596 - acc: 0.7167\n",
      "Epoch 15/150\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6460 - acc: 0.669 - 0s 541us/step - loss: 0.6403 - acc: 0.6750\n",
      "Epoch 16/150\n",
      "120/120 [==============================] - 0s 525us/step - loss: 0.6157 - acc: 0.8917\n",
      "Epoch 17/150\n",
      "120/120 [==============================] - 0s 575us/step - loss: 0.5961 - acc: 0.7333\n",
      "Epoch 18/150\n",
      "120/120 [==============================] - 0s 550us/step - loss: 0.5793 - acc: 0.8583\n",
      "Epoch 19/150\n",
      "120/120 [==============================] - 0s 591us/step - loss: 0.5570 - acc: 0.8833\n",
      "Epoch 20/150\n",
      "120/120 [==============================] - 0s 533us/step - loss: 0.5442 - acc: 0.7833 0s - loss: 0.5454 - acc: 0.773\n",
      "Epoch 21/150\n",
      "120/120 [==============================] - 0s 558us/step - loss: 0.5266 - acc: 0.9083\n",
      "Epoch 22/150\n",
      "120/120 [==============================] - 0s 483us/step - loss: 0.5174 - acc: 0.7750\n",
      "Epoch 23/150\n",
      "120/120 [==============================] - 0s 600us/step - loss: 0.4992 - acc: 0.9417\n",
      "Epoch 24/150\n",
      "120/120 [==============================] - 0s 608us/step - loss: 0.4913 - acc: 0.9083\n",
      "Epoch 25/150\n",
      "120/120 [==============================] - 0s 583us/step - loss: 0.4762 - acc: 0.9250\n",
      "Epoch 26/150\n",
      "120/120 [==============================] - 0s 600us/step - loss: 0.4677 - acc: 0.9250\n",
      "Epoch 27/150\n",
      "120/120 [==============================] - 0s 616us/step - loss: 0.4548 - acc: 0.9417\n",
      "Epoch 28/150\n",
      "120/120 [==============================] - 0s 625us/step - loss: 0.4457 - acc: 0.9417\n",
      "Epoch 29/150\n",
      "120/120 [==============================] - 0s 575us/step - loss: 0.4449 - acc: 0.9250\n",
      "Epoch 30/150\n",
      "120/120 [==============================] - 0s 591us/step - loss: 0.4271 - acc: 0.9667\n",
      "Epoch 31/150\n",
      "120/120 [==============================] - 0s 558us/step - loss: 0.4210 - acc: 0.9417\n",
      "Epoch 32/150\n",
      "120/120 [==============================] - 0s 583us/step - loss: 0.4132 - acc: 0.9500\n",
      "Epoch 33/150\n",
      "120/120 [==============================] - 0s 541us/step - loss: 0.4038 - acc: 0.9417 0s - loss: 0.4058 - acc: 0.945\n",
      "Epoch 34/150\n",
      "120/120 [==============================] - 0s 583us/step - loss: 0.3936 - acc: 0.9583\n",
      "Epoch 35/150\n",
      "120/120 [==============================] - 0s 441us/step - loss: 0.3877 - acc: 0.9500\n",
      "Epoch 36/150\n",
      "120/120 [==============================] - 0s 525us/step - loss: 0.3795 - acc: 0.9583\n",
      "Epoch 37/150\n",
      "120/120 [==============================] - 0s 700us/step - loss: 0.3753 - acc: 0.9667\n",
      "Epoch 38/150\n",
      "120/120 [==============================] - 0s 541us/step - loss: 0.3641 - acc: 0.9667\n",
      "Epoch 39/150\n",
      "120/120 [==============================] - 0s 566us/step - loss: 0.3619 - acc: 0.9750\n",
      "Epoch 40/150\n",
      "120/120 [==============================] - 0s 616us/step - loss: 0.3554 - acc: 0.9500\n",
      "Epoch 41/150\n",
      "120/120 [==============================] - 0s 575us/step - loss: 0.3464 - acc: 0.9750\n",
      "Epoch 42/150\n",
      "120/120 [==============================] - 0s 533us/step - loss: 0.3417 - acc: 0.9583\n",
      "Epoch 43/150\n",
      "120/120 [==============================] - 0s 458us/step - loss: 0.3413 - acc: 0.9583\n",
      "Epoch 44/150\n",
      "120/120 [==============================] - 0s 466us/step - loss: 0.3385 - acc: 0.9500\n",
      "Epoch 45/150\n",
      "120/120 [==============================] - 0s 558us/step - loss: 0.3311 - acc: 0.9750\n",
      "Epoch 46/150\n",
      "120/120 [==============================] - 0s 533us/step - loss: 0.3269 - acc: 0.9250\n",
      "Epoch 47/150\n",
      "120/120 [==============================] - 0s 450us/step - loss: 0.3163 - acc: 0.9667\n",
      "Epoch 48/150\n",
      "120/120 [==============================] - 0s 516us/step - loss: 0.3105 - acc: 0.9750\n",
      "Epoch 49/150\n",
      "120/120 [==============================] - 0s 450us/step - loss: 0.3053 - acc: 0.9750\n",
      "Epoch 50/150\n",
      "120/120 [==============================] - 0s 591us/step - loss: 0.3029 - acc: 0.9583\n",
      "Epoch 51/150\n",
      "120/120 [==============================] - 0s 475us/step - loss: 0.2979 - acc: 0.9667\n",
      "Epoch 52/150\n",
      "120/120 [==============================] - 0s 541us/step - loss: 0.2964 - acc: 0.9667\n",
      "Epoch 53/150\n",
      "120/120 [==============================] - 0s 516us/step - loss: 0.2862 - acc: 0.9667\n",
      "Epoch 54/150\n",
      "120/120 [==============================] - 0s 433us/step - loss: 0.2829 - acc: 0.9750\n",
      "Epoch 55/150\n",
      "120/120 [==============================] - 0s 500us/step - loss: 0.2811 - acc: 0.9750\n",
      "Epoch 56/150\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2779 - acc: 0.960 - 0s 600us/step - loss: 0.2727 - acc: 0.9667\n",
      "Epoch 57/150\n",
      "120/120 [==============================] - 0s 441us/step - loss: 0.2713 - acc: 0.9667\n",
      "Epoch 58/150\n",
      "120/120 [==============================] - 0s 483us/step - loss: 0.2655 - acc: 0.9667\n",
      "Epoch 59/150\n",
      "120/120 [==============================] - 0s 450us/step - loss: 0.2621 - acc: 0.9667\n",
      "Epoch 60/150\n",
      "120/120 [==============================] - 0s 525us/step - loss: 0.2601 - acc: 0.9583\n",
      "Epoch 61/150\n",
      "120/120 [==============================] - 0s 575us/step - loss: 0.2552 - acc: 0.9750\n",
      "Epoch 62/150\n",
      "120/120 [==============================] - 0s 541us/step - loss: 0.2505 - acc: 0.9750\n",
      "Epoch 63/150\n",
      "120/120 [==============================] - 0s 416us/step - loss: 0.2512 - acc: 0.9583\n",
      "Epoch 64/150\n",
      "120/120 [==============================] - 0s 441us/step - loss: 0.2483 - acc: 0.9750\n",
      "Epoch 65/150\n",
      "120/120 [==============================] - 0s 433us/step - loss: 0.2413 - acc: 0.9750\n",
      "Epoch 66/150\n",
      "120/120 [==============================] - 0s 433us/step - loss: 0.2444 - acc: 0.9583\n",
      "Epoch 67/150\n",
      "120/120 [==============================] - 0s 408us/step - loss: 0.2346 - acc: 0.9750\n",
      "Epoch 68/150\n",
      "120/120 [==============================] - 0s 475us/step - loss: 0.2343 - acc: 0.9667\n",
      "Epoch 69/150\n",
      "120/120 [==============================] - 0s 433us/step - loss: 0.2282 - acc: 0.9750\n",
      "Epoch 70/150\n",
      "120/120 [==============================] - 0s 450us/step - loss: 0.2257 - acc: 0.9750\n",
      "Epoch 71/150\n",
      "120/120 [==============================] - 0s 433us/step - loss: 0.2214 - acc: 0.9750\n",
      "Epoch 72/150\n",
      "120/120 [==============================] - 0s 416us/step - loss: 0.2200 - acc: 0.9750\n",
      "Epoch 73/150\n",
      "120/120 [==============================] - 0s 408us/step - loss: 0.2185 - acc: 0.9667\n",
      "Epoch 74/150\n",
      "120/120 [==============================] - 0s 566us/step - loss: 0.2151 - acc: 0.9667\n",
      "Epoch 75/150\n",
      "120/120 [==============================] - 0s 533us/step - loss: 0.2145 - acc: 0.9583\n",
      "Epoch 76/150\n",
      "120/120 [==============================] - 0s 525us/step - loss: 0.2144 - acc: 0.9667\n",
      "Epoch 77/150\n",
      "120/120 [==============================] - 0s 466us/step - loss: 0.2061 - acc: 0.9750\n",
      "Epoch 78/150\n",
      "120/120 [==============================] - 0s 450us/step - loss: 0.2054 - acc: 0.9833\n",
      "Epoch 79/150\n",
      "120/120 [==============================] - 0s 433us/step - loss: 0.2020 - acc: 0.9750\n",
      "Epoch 80/150\n",
      "120/120 [==============================] - 0s 416us/step - loss: 0.1990 - acc: 0.9667\n",
      "Epoch 81/150\n",
      "120/120 [==============================] - 0s 425us/step - loss: 0.1979 - acc: 0.9750\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 366us/step - loss: 0.1953 - acc: 0.9750\n",
      "Epoch 83/150\n",
      "120/120 [==============================] - 0s 416us/step - loss: 0.1940 - acc: 0.9667\n",
      "Epoch 84/150\n",
      "120/120 [==============================] - 0s 533us/step - loss: 0.1928 - acc: 0.9667\n",
      "Epoch 85/150\n",
      "120/120 [==============================] - 0s 525us/step - loss: 0.1879 - acc: 0.9750\n",
      "Epoch 86/150\n",
      "120/120 [==============================] - 0s 410us/step - loss: 0.1859 - acc: 0.9750\n",
      "Epoch 87/150\n",
      "120/120 [==============================] - 0s 415us/step - loss: 0.1885 - acc: 0.9583\n",
      "Epoch 88/150\n",
      "120/120 [==============================] - 0s 375us/step - loss: 0.1847 - acc: 0.9833\n",
      "Epoch 89/150\n",
      "120/120 [==============================] - 0s 408us/step - loss: 0.1852 - acc: 0.9667\n",
      "Epoch 90/150\n",
      "120/120 [==============================] - 0s 375us/step - loss: 0.1859 - acc: 0.9667\n",
      "Epoch 91/150\n",
      "120/120 [==============================] - 0s 416us/step - loss: 0.1810 - acc: 0.9667\n",
      "Epoch 92/150\n",
      "120/120 [==============================] - 0s 400us/step - loss: 0.1828 - acc: 0.9750\n",
      "Epoch 93/150\n",
      "120/120 [==============================] - 0s 550us/step - loss: 0.1764 - acc: 0.9667\n",
      "Epoch 94/150\n",
      "120/120 [==============================] - 0s 583us/step - loss: 0.1764 - acc: 0.9500\n",
      "Epoch 95/150\n",
      "120/120 [==============================] - 0s 450us/step - loss: 0.1690 - acc: 0.9667\n",
      "Epoch 96/150\n",
      "120/120 [==============================] - 0s 400us/step - loss: 0.1667 - acc: 0.9750\n",
      "Epoch 97/150\n",
      "120/120 [==============================] - 0s 383us/step - loss: 0.1669 - acc: 0.9750\n",
      "Epoch 98/150\n",
      "120/120 [==============================] - 0s 408us/step - loss: 0.1646 - acc: 0.9750\n",
      "Epoch 99/150\n",
      "120/120 [==============================] - 0s 450us/step - loss: 0.1638 - acc: 0.9667\n",
      "Epoch 100/150\n",
      "120/120 [==============================] - 0s 450us/step - loss: 0.1616 - acc: 0.9667\n",
      "Epoch 101/150\n",
      "120/120 [==============================] - 0s 441us/step - loss: 0.1599 - acc: 0.9750\n",
      "Epoch 102/150\n",
      "120/120 [==============================] - 0s 425us/step - loss: 0.1596 - acc: 0.9750\n",
      "Epoch 103/150\n",
      "120/120 [==============================] - 0s 591us/step - loss: 0.1565 - acc: 0.9750\n",
      "Epoch 104/150\n",
      "120/120 [==============================] - 0s 541us/step - loss: 0.1543 - acc: 0.9667\n",
      "Epoch 105/150\n",
      "120/120 [==============================] - 0s 433us/step - loss: 0.1559 - acc: 0.9583\n",
      "Epoch 106/150\n",
      "120/120 [==============================] - 0s 425us/step - loss: 0.1528 - acc: 0.9750\n",
      "Epoch 107/150\n",
      "120/120 [==============================] - 0s 425us/step - loss: 0.1518 - acc: 0.9750\n",
      "Epoch 108/150\n",
      "120/120 [==============================] - 0s 425us/step - loss: 0.1557 - acc: 0.9833\n",
      "Epoch 109/150\n",
      "120/120 [==============================] - 0s 383us/step - loss: 0.1553 - acc: 0.9667\n",
      "Epoch 110/150\n",
      "120/120 [==============================] - 0s 383us/step - loss: 0.1447 - acc: 0.9750\n",
      "Epoch 111/150\n",
      "120/120 [==============================] - 0s 475us/step - loss: 0.1462 - acc: 0.9750\n",
      "Epoch 112/150\n",
      "120/120 [==============================] - 0s 441us/step - loss: 0.1455 - acc: 0.9667\n",
      "Epoch 113/150\n",
      "120/120 [==============================] - 0s 400us/step - loss: 0.1448 - acc: 0.9667\n",
      "Epoch 114/150\n",
      "120/120 [==============================] - 0s 383us/step - loss: 0.1415 - acc: 0.9750\n",
      "Epoch 115/150\n",
      "120/120 [==============================] - 0s 400us/step - loss: 0.1408 - acc: 0.9750\n",
      "Epoch 116/150\n",
      "120/120 [==============================] - 0s 441us/step - loss: 0.1409 - acc: 0.9750\n",
      "Epoch 117/150\n",
      "120/120 [==============================] - 0s 425us/step - loss: 0.1392 - acc: 0.9667\n",
      "Epoch 118/150\n",
      "120/120 [==============================] - 0s 458us/step - loss: 0.1403 - acc: 0.9750\n",
      "Epoch 119/150\n",
      "120/120 [==============================] - 0s 441us/step - loss: 0.1378 - acc: 0.9667\n",
      "Epoch 120/150\n",
      "120/120 [==============================] - 0s 416us/step - loss: 0.1387 - acc: 0.9667\n",
      "Epoch 121/150\n",
      "120/120 [==============================] - 0s 383us/step - loss: 0.1351 - acc: 0.9667\n",
      "Epoch 122/150\n",
      "120/120 [==============================] - 0s 391us/step - loss: 0.1327 - acc: 0.9750\n",
      "Epoch 123/150\n",
      "120/120 [==============================] - 0s 425us/step - loss: 0.1322 - acc: 0.9750\n",
      "Epoch 124/150\n",
      "120/120 [==============================] - 0s 425us/step - loss: 0.1314 - acc: 0.9750\n",
      "Epoch 125/150\n",
      "120/120 [==============================] - 0s 675us/step - loss: 0.1319 - acc: 0.9750\n",
      "Epoch 126/150\n",
      "120/120 [==============================] - 0s 533us/step - loss: 0.1317 - acc: 0.9750\n",
      "Epoch 127/150\n",
      "120/120 [==============================] - 0s 433us/step - loss: 0.1301 - acc: 0.9750\n",
      "Epoch 128/150\n",
      "120/120 [==============================] - 0s 450us/step - loss: 0.1289 - acc: 0.9667\n",
      "Epoch 129/150\n",
      "120/120 [==============================] - 0s 516us/step - loss: 0.1286 - acc: 0.9667\n",
      "Epoch 130/150\n",
      "120/120 [==============================] - 0s 441us/step - loss: 0.1318 - acc: 0.9583\n",
      "Epoch 131/150\n",
      "120/120 [==============================] - 0s 491us/step - loss: 0.1303 - acc: 0.9667\n",
      "Epoch 132/150\n",
      "120/120 [==============================] - 0s 441us/step - loss: 0.1303 - acc: 0.9583\n",
      "Epoch 133/150\n",
      "120/120 [==============================] - 0s 600us/step - loss: 0.1228 - acc: 0.9750\n",
      "Epoch 134/150\n",
      "120/120 [==============================] - 0s 591us/step - loss: 0.1225 - acc: 0.9667\n",
      "Epoch 135/150\n",
      "120/120 [==============================] - 0s 575us/step - loss: 0.1262 - acc: 0.9750\n",
      "Epoch 136/150\n",
      "120/120 [==============================] - 0s 608us/step - loss: 0.1242 - acc: 0.9667\n",
      "Epoch 137/150\n",
      "120/120 [==============================] - 0s 550us/step - loss: 0.1209 - acc: 0.9667\n",
      "Epoch 138/150\n",
      "120/120 [==============================] - 0s 625us/step - loss: 0.1209 - acc: 0.9750\n",
      "Epoch 139/150\n",
      "120/120 [==============================] - 0s 575us/step - loss: 0.1178 - acc: 0.9750\n",
      "Epoch 140/150\n",
      "120/120 [==============================] - 0s 583us/step - loss: 0.1179 - acc: 0.9667\n",
      "Epoch 141/150\n",
      "120/120 [==============================] - 0s 525us/step - loss: 0.1184 - acc: 0.9750\n",
      "Epoch 142/150\n",
      "120/120 [==============================] - 0s 533us/step - loss: 0.1174 - acc: 0.9750\n",
      "Epoch 143/150\n",
      "120/120 [==============================] - 0s 525us/step - loss: 0.1156 - acc: 0.9667\n",
      "Epoch 144/150\n",
      "120/120 [==============================] - 0s 508us/step - loss: 0.1167 - acc: 0.9667\n",
      "Epoch 145/150\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1140 - acc: 0.978 - 0s 600us/step - loss: 0.1143 - acc: 0.9750\n",
      "Epoch 146/150\n",
      "120/120 [==============================] - 0s 508us/step - loss: 0.1133 - acc: 0.9750\n",
      "Epoch 147/150\n",
      "120/120 [==============================] - 0s 575us/step - loss: 0.1125 - acc: 0.9750\n",
      "Epoch 148/150\n",
      "120/120 [==============================] - 0s 558us/step - loss: 0.1143 - acc: 0.9750\n",
      "Epoch 149/150\n",
      "120/120 [==============================] - 0s 541us/step - loss: 0.1126 - acc: 0.9750\n",
      "Epoch 150/150\n",
      "120/120 [==============================] - 0s 516us/step - loss: 0.1123 - acc: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2725d047550>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step\n",
      "\n",
      "acc: 96.67%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los pesos de la capa 0: \n",
      " [[ 0.6879192   1.027729    0.23832688  0.28149384 -0.24097238 -0.32083574\n",
      "   0.09654245 -0.24681091 -0.38728964  0.28540212 -0.2895755  -0.12873107\n",
      "  -0.27290514  0.47960132 -0.16924262  0.18743744]\n",
      " [-0.08452196  0.7748494  -0.7971831  -0.45667416 -0.27307832 -0.30360162\n",
      "   0.0087458  -0.12751636  0.25607675 -0.45289114  0.38897616 -0.4786837\n",
      "   0.2862532   1.0586693  -0.3017729  -0.58322597]\n",
      " [ 0.6348956  -0.63204485  0.04571527 -0.49880263  0.8026024   0.03566074\n",
      "  -0.36305746  0.01405573  0.05625397  0.16342498 -0.1546501   0.03476465\n",
      "  -0.19107747 -0.03845914 -0.17534158  0.66913533]\n",
      " [ 0.29454336 -1.1381596   0.98611087  0.39851242  0.8310197  -0.1791\n",
      "  -0.45925748  0.2927724  -0.44956458 -0.12593642  0.35841343 -0.30742925\n",
      "  -0.53649884 -0.27094552 -0.17885816  0.6757126 ]] \n",
      "\n",
      "Dimensiones del Bias de la capa 0: \n",
      " [ 0.42305782  0.8673452  -0.47923553  0.         -0.38130704  0.\n",
      " -0.06785009  0.          0.          0.04286429 -0.01093684  0.\n",
      "  0.          0.27937767  0.         -0.22140896] \n"
     ]
    }
   ],
   "source": [
    "n_layer = 0\n",
    "B_Input_Hidden = model.layers[n_layer].get_weights()\n",
    "print(\"Dimensiones de los pesos de la capa {}: \\n {} \\n\".format(n_layer,B_Input_Hidden[0]))\n",
    "print(\"Dimensiones del Bias de la capa {}: \\n {} \".format(n_layer,B_Input_Hidden[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los pesos de la capa 1: \n",
      " [[-0.9285466  -0.00947846 -0.42134324]\n",
      " [ 0.57885015  0.02108198 -1.0007355 ]\n",
      " [-0.4177649  -0.9973735   1.2575829 ]\n",
      " [-0.02497649  0.18526626  0.1308018 ]\n",
      " [-1.3341012  -0.53920025  0.9432397 ]\n",
      " [ 0.23410201 -0.2848405  -0.401398  ]\n",
      " [-0.49265578  0.03694439 -0.02681982]\n",
      " [-0.48015767 -0.01647884  0.08020812]\n",
      " [-0.4810232   0.23577195  0.4187513 ]\n",
      " [-0.85200304  0.33393592 -0.01484706]\n",
      " [-0.35719448 -0.15947568 -0.08850373]\n",
      " [-0.11973548 -0.02175778  0.3005815 ]\n",
      " [ 0.525533    0.46670657 -0.4073873 ]\n",
      " [ 0.18887398 -0.76088506 -0.6123799 ]\n",
      " [-0.18257904 -0.5143805   0.03696311]\n",
      " [-1.977876   -0.34474075  0.49153057]] \n",
      "\n",
      "Dimensiones del Bias de la capa 1: \n",
      "[ 0.09769254 -0.01791726 -0.67817557] \n"
     ]
    }
   ],
   "source": [
    "n_layer = 1\n",
    "B_Input_Hidden =  model.layers[n_layer].get_weights()\n",
    "print(\"Dimensiones de los pesos de la capa {}: \\n {} \\n\".format(n_layer,B_Input_Hidden[0]))\n",
    "print(\"Dimensiones del Bias de la capa {}: \\n{} \".format(n_layer,B_Input_Hidden[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a =  model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6879192   1.027729    0.23832688  0.28149384 -0.24097238 -0.32083574\n",
      "  0.09654245 -0.24681091 -0.38728964  0.28540212 -0.2895755  -0.12873107\n",
      " -0.27290514  0.47960132 -0.16924262  0.18743744]\n",
      "[-0.08452196  0.7748494  -0.7971831  -0.45667416 -0.27307832 -0.30360162\n",
      "  0.0087458  -0.12751636  0.25607675 -0.45289114  0.38897616 -0.4786837\n",
      "  0.2862532   1.0586693  -0.3017729  -0.58322597]\n",
      "[ 0.6348956  -0.63204485  0.04571527 -0.49880263  0.8026024   0.03566074\n",
      " -0.36305746  0.01405573  0.05625397  0.16342498 -0.1546501   0.03476465\n",
      " -0.19107747 -0.03845914 -0.17534158  0.66913533]\n",
      "[ 0.29454336 -1.1381596   0.98611087  0.39851242  0.8310197  -0.1791\n",
      " -0.45925748  0.2927724  -0.44956458 -0.12593642  0.35841343 -0.30742925\n",
      " -0.53649884 -0.27094552 -0.17885816  0.6757126 ]\n"
     ]
    }
   ],
   "source": [
    "for u in range(0, 4):\n",
    "    #for i in range(0, 15):\n",
    "    print(a[0][u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b =  model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9285466  -0.00947846 -0.42134324]\n",
      "[ 0.57885015  0.02108198 -1.0007355 ]\n",
      "[-0.4177649 -0.9973735  1.2575829]\n",
      "[-0.02497649  0.18526626  0.1308018 ]\n",
      "[-1.3341012  -0.53920025  0.9432397 ]\n",
      "[ 0.23410201 -0.2848405  -0.401398  ]\n",
      "[-0.49265578  0.03694439 -0.02681982]\n",
      "[-0.48015767 -0.01647884  0.08020812]\n",
      "[-0.4810232   0.23577195  0.4187513 ]\n",
      "[-0.85200304  0.33393592 -0.01484706]\n",
      "[-0.35719448 -0.15947568 -0.08850373]\n",
      "[-0.11973548 -0.02175778  0.3005815 ]\n",
      "[ 0.525533    0.46670657 -0.4073873 ]\n",
      "[ 0.18887398 -0.76088506 -0.6123799 ]\n",
      "[-0.18257904 -0.5143805   0.03696311]\n",
      "[-1.977876   -0.34474075  0.49153057]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 16):\n",
    "    print(b[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.9, 3.1, 1.5, 0.1], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.1, 2.8, 4.7, 1.2],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6.0, 2.9, 4.5, 1.5],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6.5, 3.2, 5.1, 2.0],\n",
       "       [4.8, 3.0, 1.4, 0.1],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [6.5, 3.0, 5.8, 2.2],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [6.1, 3.0, 4.9, 1.8],\n",
       "       [5.0, 3.4, 1.6, 0.4],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.9, 3.8, 6.4, 2.0],\n",
       "       [6.7, 3.0, 5.2, 2.3],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [4.8, 3.0, 1.4, 0.3],\n",
       "       [4.8, 3.1, 1.6, 0.2]], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1 2.8 4.7 1.2]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4570844e-06, 1.7659620e-03, 1.8663656e-04],\n",
       "       [7.6783055e-01, 6.2300544e-03, 2.1622650e-07],\n",
       "       [3.3424522e-12, 3.8725717e-05, 4.4549957e-02],\n",
       "       [1.3369430e-06, 1.3537904e-03, 3.4277872e-04],\n",
       "       [3.8158436e-07, 9.0561307e-04, 1.5976440e-04],\n",
       "       [6.8588024e-01, 9.4965296e-03, 6.6182321e-07],\n",
       "       [7.6295837e-05, 3.8450910e-03, 7.7180397e-05],\n",
       "       [1.0852472e-08, 1.9246152e-04, 2.1903629e-03],\n",
       "       [1.5672400e-07, 1.0780724e-03, 1.9878547e-03],\n",
       "       [2.0001122e-05, 3.2886674e-03, 1.1374019e-04],\n",
       "       [5.1359780e-08, 3.6834128e-04, 1.0115491e-03],\n",
       "       [7.2878158e-01, 1.5700946e-02, 1.9658992e-06],\n",
       "       [8.0688912e-01, 8.3354432e-03, 3.4421893e-07],\n",
       "       [7.2509927e-01, 1.4047423e-02, 1.5140635e-06],\n",
       "       [8.2074207e-01, 7.1942243e-03, 5.2775823e-07],\n",
       "       [1.3443713e-06, 9.7541272e-04, 1.3299398e-04],\n",
       "       [1.1489018e-09, 1.6597389e-04, 1.0653295e-02],\n",
       "       [1.7208909e-05, 4.0032468e-03, 1.9170129e-04],\n",
       "       [2.3262305e-06, 2.0448861e-03, 3.4990197e-04],\n",
       "       [1.3279385e-09, 1.8917029e-04, 1.6202044e-02],\n",
       "       [7.1558374e-01, 1.3733935e-02, 2.1314308e-06],\n",
       "       [1.3892236e-07, 6.4747105e-04, 1.1781770e-03],\n",
       "       [6.8249482e-01, 1.0599729e-02, 1.3078735e-06],\n",
       "       [1.9289170e-09, 2.2037700e-04, 1.1428366e-02],\n",
       "       [1.9424706e-09, 9.9090728e-05, 1.6720318e-04],\n",
       "       [6.0833094e-09, 1.9256541e-04, 4.5621926e-03],\n",
       "       [1.0846011e-09, 2.5350443e-04, 8.3845081e-03],\n",
       "       [9.0766600e-10, 1.2241225e-04, 6.3971193e-03],\n",
       "       [6.6340053e-01, 1.5762590e-02, 2.5753045e-06],\n",
       "       [6.5505111e-01, 1.4318815e-02, 2.1612457e-06]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|----------------------------------------------------------|\n",
      "|         Welcome to Iris Neural Network, by Sandro        |\n",
      "|        Labels prediction accuaracy TensorFlow(100%)      |\n",
      "|----------------------------------------------------------|\n",
      "|      features       |   real labels   |  predic labels   |\n",
      "|---------------------|-----------------|------------------|\n",
      "| 6.1  2.8  4.7  1.2  |  0.0  1.0  0.0  | 0.00  0.02  0.00 |\n",
      "| 5.7  3.8  1.7  0.3  |  1.0  0.0  0.0  | 7.68  0.06  0.00 |\n",
      "| 7.7  2.6  6.9  2.3  |  0.0  0.0  1.0  | 0.00  0.00  0.45 |\n",
      "| 6.0  2.9  4.5  1.5  |  0.0  1.0  0.0  | 0.00  0.01  0.00 |\n",
      "| 6.8  2.8  4.8  1.4  |  0.0  1.0  0.0  | 0.00  0.01  0.00 |\n",
      "| 5.4  3.4  1.5  0.4  |  1.0  0.0  0.0  | 6.86  0.09  0.00 |\n",
      "| 5.6  2.9  3.6  1.3  |  0.0  1.0  0.0  | 0.00  0.04  0.00 |\n",
      "| 6.9  3.1  5.1  2.3  |  0.0  0.0  1.0  | 0.00  0.00  0.02 |\n",
      "| 6.2  2.2  4.5  1.5  |  0.0  1.0  0.0  | 0.00  0.01  0.02 |\n",
      "| 5.8  2.7  3.9  1.2  |  0.0  1.0  0.0  | 0.00  0.03  0.00 |\n",
      "| 6.5  3.2  5.1  2.0  |  0.0  0.0  1.0  | 0.00  0.00  0.01 |\n",
      "| 4.8  3.0  1.4  0.1  |  1.0  0.0  0.0  | 7.29  0.16  0.00 |\n",
      "| 5.5  3.5  1.3  0.2  |  1.0  0.0  0.0  | 8.07  0.08  0.00 |\n",
      "| 4.9  3.1  1.5  0.1  |  1.0  0.0  0.0  | 7.25  0.14  0.00 |\n",
      "| 5.1  3.8  1.5  0.3  |  1.0  0.0  0.0  | 8.21  0.07  0.00 |\n",
      "| 6.3  3.3  4.7  1.6  |  0.0  1.0  0.0  | 0.00  0.01  0.00 |\n",
      "| 6.5  3.0  5.8  2.2  |  0.0  0.0  1.0  | 0.00  0.00  0.11 |\n",
      "| 5.6  2.5  3.9  1.1  |  0.0  1.0  0.0  | 0.00  0.04  0.00 |\n",
      "| 5.7  2.8  4.5  1.3  |  0.0  1.0  0.0  | 0.00  0.02  0.00 |\n",
      "| 6.4  2.8  5.6  2.2  |  0.0  0.0  1.0  | 0.00  0.00  0.16 |\n",
      "| 4.7  3.2  1.6  0.2  |  1.0  0.0  0.0  | 7.16  0.14  0.00 |\n",
      "| 6.1  3.0  4.9  1.8  |  0.0  0.0  1.0  | 0.00  0.01  0.01 |\n",
      "| 5.0  3.4  1.6  0.4  |  1.0  0.0  0.0  | 6.82  0.11  0.00 |\n",
      "| 6.4  2.8  5.6  2.1  |  0.0  0.0  1.0  | 0.00  0.00  0.11 |\n",
      "| 7.9  3.8  6.4  2.0  |  0.0  0.0  1.0  | 0.00  0.00  0.00 |\n",
      "| 6.7  3.0  5.2  2.3  |  0.0  0.0  1.0  | 0.00  0.00  0.05 |\n",
      "| 6.7  2.5  5.8  1.8  |  0.0  0.0  1.0  | 0.00  0.00  0.08 |\n",
      "| 6.8  3.2  5.9  2.3  |  0.0  0.0  1.0  | 0.00  0.00  0.06 |\n",
      "| 4.8  3.0  1.4  0.3  |  1.0  0.0  0.0  | 6.63  0.16  0.00 |\n",
      "| 4.8  3.1  1.6  0.2  |  1.0  0.0  0.0  | 6.55  0.14  0.00 |\n",
      "|----------------------------------------------------------|\n"
     ]
    }
   ],
   "source": [
    "valmult = 10\n",
    "print(\"|----------------------------------------------------------|\")\n",
    "print(\"|         Welcome to Iris Neural Network, by Sandro        |\")\n",
    "print(\"|        Labels prediction accuaracy TensorFlow(100%)      |\")\n",
    "print(\"|----------------------------------------------------------|\")\n",
    "print(\"|      features       |   real labels   |  predic labels   |\")\n",
    "print(\"|---------------------|-----------------|------------------|\")\n",
    "for i in range(0,30):\n",
    "    print( \"| {}  {}  {}  {}  |  {}  {}  {}  | {:3.2f}  {:3.2f}  {:3.2f} |\" .\n",
    "          format(X_test[i][0], X_test[i][1],X_test[i][2],X_test[i][3], y_test[i][0], y_test[i][1],y_test[i][2],\n",
    "                 valmult*predictions[i][0], valmult*predictions[i][1], valmult*predictions[i][2]) ) \n",
    "    \n",
    "print(\"|----------------------------------------------------------|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
